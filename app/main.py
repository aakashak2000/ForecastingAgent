from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import logging
import time
from datetime import datetime
from typing import Optional
from contextlib import asynccontextmanager

from agent.orchestrator import FinancialForecastingAgent
from app.database import log_request_response, init_database, get_database_stats, db_manager

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Initialize agent
agent = FinancialForecastingAgent()

@asynccontextmanager
async def lifespan(app: FastAPI):
    """Application lifespan event handler"""
    # Startup
    logger.info("ðŸš€ Starting Financial Forecasting Agent...")
    
    # Initialize database
    await init_database()
    
    # Auto-setup RAG data if needed
    await setup_rag_data_if_needed()
    
    logger.info("âœ… Financial Forecasting Agent API started successfully")
    
    yield
    
    # Shutdown
    logger.info("ðŸ”„ Shutting down Financial Forecasting Agent...")

async def setup_rag_data_if_needed():
    """Automatically download and setup quality RAG data for major companies"""
    try:
        from vector_store.transcript_vectorstore import TranscriptVectorStore
        from utils.data_downloader import ScreenerDataDownloader
        
        # Check if vector store has quality data
        vectorstore = TranscriptVectorStore(persist_directory="data/vector_store")
        stats = vectorstore.get_collection_stats()
        
        if stats.get('total_chunks', 0) > 50:  # Require substantial data
            logger.info(f"âœ… Quality RAG data exists: {stats['total_chunks']} chunks, avg quality: {stats.get('average_quality_score', 0):.3f}")
            return
        
        logger.info("ðŸ”„ Setting up quality RAG data for major companies...")
        
        # Setup data for major companies to ensure evaluator can test any of them
        major_companies = ["TCS", "INFY", "RELIANCE"]
        downloader = ScreenerDataDownloader()
        total_chunks_all = 0
        
        for company in major_companies:
            try:
                logger.info(f"ðŸ“¥ Downloading {company} transcript data...")
                results = downloader.get_latest_documents(company, max_reports=0, max_transcripts=3)
                
                company_chunks = 0
                if results['transcripts']:
                    for transcript in results['transcripts']:
                        content = transcript.get('full_content', transcript.get('content', ''))
                        if len(content) > 2000:  # Quality threshold
                            chunks_added = vectorstore.add_transcript(
                                transcript_text=content,
                                company_symbol=company,
                                transcript_date=transcript['date'],
                                source_info={'source': 'earnings_call', 'startup_setup': True}
                            )
                            company_chunks += chunks_added
                            total_chunks_all += chunks_added
                
                if company_chunks > 0:
                    logger.info(f"âœ… {company}: {company_chunks} quality chunks added")
                else:
                    logger.warning(f"âš ï¸ {company}: No quality transcript data found")
                
            except Exception as e:
                logger.warning(f"âš ï¸ Failed to setup {company}: {e}")
                continue
        
        # Final quality check
        final_stats = vectorstore.get_collection_stats()
        if total_chunks_all > 0:
            logger.info(f"âœ… Quality RAG setup complete:")
            logger.info(f"   Total chunks: {final_stats.get('total_chunks', 0)}")
            logger.info(f"   Companies: {final_stats.get('companies', [])}")
            logger.info(f"   Average quality: {final_stats.get('average_quality_score', 0):.3f}")
            logger.info(f"   Quality status: {final_stats.get('quality_status', 'unknown')}")
        else:
            logger.warning("âš ï¸ Quality RAG setup failed - will use market data analysis only")
            
    except Exception as e:
        logger.warning(f"âš ï¸ Auto RAG setup failed: {e} - will continue with market analysis only")

# Create FastAPI app with lifespan
app = FastAPI(
    title="Financial Forecasting Agent",
    description="AI-powered financial analysis combining market data, earnings transcripts, and quantitative metrics",
    version="1.0.0",
    lifespan=lifespan
)

class ForecastRequest(BaseModel):
    company_symbol: str
    forecast_period: Optional[str] = "Q2-2025"

class ForecastResponse(BaseModel):
    """Business-grade structured forecast response"""
    
    # Executive Summary
    company_symbol: str
    forecast_period: str
    overall_outlook: str
    investment_recommendation: str
    analyst_confidence: float
    
    # Financial Analysis
    current_price: Optional[float] = None
    market_cap_crores: Optional[float] = None
    pe_ratio: Optional[float] = None
    price_change_percent: Optional[float] = None
    target_price: Optional[float] = None
    target_upside_percent: Optional[float] = None
    
    # Market Context
    valuation_assessment: Optional[str] = None
    price_momentum: Optional[str] = None
    risk_level: Optional[str] = None
    range_position_percent: Optional[float] = None
    
    # Management Insights
    management_sentiment: Optional[str] = None
    management_optimism_score: Optional[float] = None
    key_themes: list = []
    
    # Business Analysis
    business_outlook_insights: list = []
    growth_opportunities: list = []
    risk_factors: list = []
    key_drivers: list = []
    
    # Metadata
    processing_time: float
    generated_at: str
    data_sources: list = ["live_market_data", "earnings_transcripts", "financial_reports"]
    success: bool = True
    error_message: Optional[str] = None

@app.post("/forecast", response_model=ForecastResponse)
async def generate_forecast(request: ForecastRequest):
    """
    Generate comprehensive financial forecast
    
    Example Request:
    {
        "company_symbol": "TCS",
        "forecast_period": "Q2-2025"
    }
    
    Returns structured business analysis with investment recommendation
    """
    start_time = time.time()
    
    try:
        logger.info(f"Generating forecast for {request.company_symbol}")
        
        # Generate comprehensive forecast using our agent
        result = agent.generate_forecast(request.company_symbol, request.forecast_period)
        
        if not result.success:
            raise HTTPException(status_code=500, detail=result.error_message)
        
        # Transform into business-grade response
        business_response = create_business_response(result, start_time)
        
        # Log to database (required deliverable)
        try:
            await log_request_response(
                endpoint="/forecast",
                request_data=request.model_dump(),
                response_data=business_response.model_dump(),
                processing_time=business_response.processing_time
            )
            logger.info(f"âœ… Successfully logged to database: {request.company_symbol}")
        except Exception as e:
            logger.error(f"âŒ Database logging failed: {e}")
        
        logger.info(f"Forecast completed: {business_response.investment_recommendation} recommendation")
        return business_response
        
    except Exception as e:
        processing_time = time.time() - start_time
        error_response = ForecastResponse(
            company_symbol=request.company_symbol,
            forecast_period=request.forecast_period,
            overall_outlook="neutral",
            investment_recommendation="hold",
            analyst_confidence=0.0,
            processing_time=processing_time,
            generated_at=datetime.now().isoformat(),
            success=False,
            error_message=str(e)
        )
        
        # Log error to database
        try:
            await log_request_response(
                endpoint="/forecast",
                request_data=request.model_dump(),
                response_data=error_response.model_dump(),
                processing_time=processing_time,
                error=str(e)
            )
        except Exception as log_error:
            logger.error(f"Failed to log error: {log_error}")
        
        raise HTTPException(status_code=500, detail=str(e))

def create_business_response(result, start_time) -> ForecastResponse:
    """Transform agent result into structured business response"""
    
    processing_time = time.time() - start_time
    
    # Calculate target price and upside
    target_price = None
    target_upside = None
    if result.market_data and result.investment_recommendation.lower() == "buy":
        target_price = result.market_data.current_price * 1.15  # 15% upside assumption
        target_upside = 15.0
    
    # Calculate range position
    range_position = None
    if result.market_data:
        range_position = ((result.market_data.current_price - result.market_data.week_52_low) / 
                         (result.market_data.week_52_high - result.market_data.week_52_low)) * 100
    
    # Extract business insights
    business_insights = []
    growth_opportunities = []
    risk_factors = []
    
    if result.qualitative_analysis:
        business_insights = [insight.insight for insight in result.qualitative_analysis.business_outlook]
        growth_opportunities = [opp.insight for opp in result.qualitative_analysis.growth_opportunities]
        risk_factors = [risk.insight for risk in result.qualitative_analysis.risk_factors]
    
    return ForecastResponse(
        company_symbol=result.company_symbol,
        forecast_period=result.forecast_period,
        overall_outlook=result.overall_outlook,
        investment_recommendation=result.investment_recommendation,
        analyst_confidence=result.confidence_score,
        
        # Financial data
        current_price=result.market_data.current_price if result.market_data else None,
        market_cap_crores=result.market_data.market_cap if result.market_data else None,
        pe_ratio=result.market_data.pe_ratio if result.market_data else None,
        price_change_percent=result.market_data.price_change_percent if result.market_data else None,
        target_price=target_price,
        target_upside_percent=target_upside,
        
        # Market context
        valuation_assessment=result.market_context.current_valuation if result.market_context else None,
        price_momentum=result.market_context.price_momentum if result.market_context else None,
        risk_level=result.market_context.risk_level if result.market_context else None,
        range_position_percent=range_position,
        
        # Management insights
        management_sentiment=result.qualitative_analysis.management_sentiment.overall_tone if result.qualitative_analysis else None,
        management_optimism_score=result.qualitative_analysis.management_sentiment.optimism_score if result.qualitative_analysis else None,
        key_themes=result.qualitative_analysis.management_sentiment.key_themes if result.qualitative_analysis else [],
        
        # Business analysis
        business_outlook_insights=business_insights,
        growth_opportunities=growth_opportunities,
        risk_factors=risk_factors,
        key_drivers=result.key_drivers,
        
        # Metadata
        processing_time=processing_time,
        generated_at=datetime.now().isoformat()
    )

@app.get("/")
async def root():
    """API health check"""
    return {
        "service": "Financial Forecasting Agent",
        "status": "operational",
        "version": "1.0.0",
        "endpoints": ["/forecast", "/health", "/debug/database"]
    }

@app.get("/health")
async def health_check():
    """Detailed health check"""
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "components": {
            "llm_manager": "operational",
            "data_downloader": "operational", 
            "vector_store": "operational",
            "market_data": "operational",
            "database": db_manager.db_type if db_manager.connection else "disconnected"
        }
    }

@app.get("/debug/database")
async def debug_database():
    """Debug database connectivity and recent logs"""
    try:
        stats = await get_database_stats()
        
        # Get recent requests from database directly
        if db_manager.db_type == "mysql":
            with db_manager.connection.cursor() as cursor:
                cursor.execute("SELECT id, company_symbol, success, created_at FROM forecast_requests ORDER BY created_at DESC LIMIT 5")
                recent_requests = cursor.fetchall()
        else:
            cursor = db_manager.connection.execute("SELECT id, company_symbol, success, created_at FROM forecast_requests ORDER BY created_at DESC LIMIT 5")
            recent_requests = cursor.fetchall()
        
        return {
            "database_stats": stats,
            "recent_requests": recent_requests,
            "connection_type": db_manager.db_type
        }
    except Exception as e:
        return {"error": str(e)}

@app.get("/debug/rag")
async def debug_rag():
    """Debug RAG system status"""
    try:
        from vector_store.transcript_vectorstore import TranscriptVectorStore
        
        vectorstore = TranscriptVectorStore(persist_directory="data/vector_store")
        stats = vectorstore.get_collection_stats()
        
        # Test a sample query
        test_results = vectorstore.search_transcripts("revenue growth", "TCS", n_results=3)
        
        return {
            "vector_store_stats": stats,
            "sample_search_results": len(test_results),
            "rag_status": "operational" if stats.get('total_chunks', 0) > 0 else "no_data"
        }
    except Exception as e:
        return {"error": str(e), "rag_status": "error"}